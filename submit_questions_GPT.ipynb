{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (2.6.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\eulal\\ideaprojects\\tcc\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ronpdf (C:\\Users\\eulal\\IdeaProjects\\TCC\\venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ronpdf (C:\\Users\\eulal\\IdeaProjects\\TCC\\venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT_3 = 'gpt-3.5-turbo-0125'\n",
    "MODEL_GPT_3_V2 = 'gpt-3.5-turbo'\n",
    "MODEL_GPT_3_LIT = 'gpt-3.5-turbo-1106' \n",
    "MODEL_GPT_4_TURBO = 'gpt-4-0125-preview'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "api_key = \"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questão = \"\"\"QUESTÃO 126  \n",
    "Um garoto comprou vários abacates na feira, mas \n",
    "descobriu que eles não estavam maduros o suficiente \n",
    "para serem consumidos. Sua mãe recomendou que ele \n",
    "colocasse os abacates em um recipiente fechado, pois \n",
    "isso aceleraria seu amadurecimento. Com certa dúvida, o \n",
    "garoto realizou esta experiência: colocou alguns abacates \n",
    "no recipiente e deixou os demais em uma fruteira aberta. \n",
    "Surpreendendo-se, ele percebeu que os frutos que estavam \n",
    "no recipiente fechado amadureceram mais rapidamente.\n",
    " A aceleração desse processo é causada por\"\"\"\n",
    "alternativas = \"\"\"\n",
    "A acúmulo de gás etileno.\n",
    "B redução da umidade do ar.\n",
    "C aumento da concentração de CO2.\n",
    "D diminuição da intensidade luminosa.\n",
    "E isolamento do contato com O2 atmosférico.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-90dKCyy5pBuNjoDAHnonfIPIPHXKs\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"A\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1709938192,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_2b778c6b35\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 305,\n",
      "    \"total_tokens\": 306\n",
      "  }\n",
      "}\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model= 'gpt-3.5-turbo',\n",
    "    max_tokens= 20,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that should answer questions in Portuguese about various topics. Completing the phrase: A resposta correta é:. You must not answer more than the letter of the alternative\"},\n",
    "        {\"role\": \"user\", \"content\": f\"com base nesse enunciado: {questão} \\n responda qual a letra da alternativa correta, entre as opções a seguir: \\n {alternativas} \\n a alternativa correta é:\"}\n",
    "    ],\n",
    "    \n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submetendo as questões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "context = \"You are going to answer questions in Portuguese about various topics. Your answers must be composed with ONLY the letter of the correct alternative, do not return anything else to the user, such as explanation and text, only the letter. Completing the phrase:  A resposta correta é: \"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = API_KEY,\n",
    ")\n",
    "\n",
    "def submit_questions(prompt):    \n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model= MODEL_GPT_3,\n",
    "            max_tokens= 10,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f'{context}'},\n",
    "                {\"role\": \"user\", \"content\": f'{prompt}'}\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise Exception( \"A resposta não pode ser gerada\")\n",
    "    # print(response.choices[0].message.content.replace('\\n', ''))\n",
    "\n",
    "    if response.choices[0].message.content == \"\" or response.choices[0].message.content == None:\n",
    "        raise Exception(\"A resposta está vazia\")\n",
    "    \n",
    "    if ( not \"A\" in response.choices[0].message.content) and ( not \"B\" in response.choices[0].message.content) and ( not \"C\" in response.choices[0].message.content) and ( not \"D\" in response.choices[0].message.content) and ( not \"E\" in response.choices[0].message.content):\n",
    "        raise Exception(\"A resposta não contém a letra da alternativa correta\")\n",
    "   \n",
    "    return response.choices[0].message.content.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questão 01\n",
      "E\n",
      "Questão 02\n",
      "A\n",
      "Questão 03\n",
      "C\n",
      "Questão 04\n",
      "B\n",
      "Questão 05\n",
      "E\n",
      "Questão 06\n",
      "C\n",
      "Questão 07\n",
      "E\n",
      "Questão 08\n",
      "A\n",
      "Questão 09\n",
      "A\n",
      "Questão 10\n",
      "A\n",
      "Questão 11\n",
      "A\n",
      "Questão 12\n",
      "C\n",
      "Questão 13\n",
      "D\n",
      "Questão 14\n",
      "C\n",
      "Questão 15\n",
      "A\n",
      "Questão 16\n",
      "C\n",
      "Questão 17\n",
      "C\n",
      "Questão 18\n",
      "E\n",
      "Questão 19\n",
      "D\n",
      "Questão 20\n",
      "C\n",
      "Questão 21\n",
      "A\n",
      "Questão 22\n",
      "D\n",
      "Questão 23\n",
      "A\n",
      "Questão 24\n",
      "B\n",
      "Questão 25\n",
      "A\n",
      "Questão 26\n",
      "C\n",
      "Questão 27\n",
      "C\n",
      "Questão 28\n",
      "A\n",
      "Questão 29\n",
      "E\n",
      "Questão 30\n",
      "B\n",
      "Questão 31\n",
      "B\n",
      "Questão 32\n",
      "D\n",
      "Questão 33\n",
      "A\n",
      "Questão 34\n",
      "C\n",
      "Questão 35\n",
      "A\n",
      "Questão 36\n",
      "D\n",
      "Questão 37\n",
      "B\n",
      "Questão 38\n",
      "D\n",
      "Questão 39\n",
      "D\n",
      "Questão 40\n",
      "B\n",
      "Questão 41\n",
      "A\n",
      "Questão 42\n",
      "A\n",
      "Questão 43\n",
      "C\n",
      "Questão 44\n",
      "A\n",
      "Questão 45\n",
      "E\n",
      "Questão 46\n",
      "A\n",
      "Questão 47\n",
      "C\n",
      "Questão 48\n",
      "E\n",
      "Questão 49\n",
      "D\n",
      "Questão 50\n",
      "D\n",
      "Questão 51\n",
      "D\n",
      "Questão 52\n",
      "C\n",
      "Questão 53\n",
      "A\n",
      "Questão 54\n",
      "B\n",
      "Questão 55\n",
      "E\n",
      "Questão 56\n",
      "E IV e V.\n",
      "Questão 57\n",
      "A\n",
      "Questão 58\n",
      "E\n",
      "Questão 59\n",
      "C\n",
      "Questão 60\n",
      "C.\n",
      "Questão 61\n",
      "C\n",
      "Questão 62\n",
      "B\n",
      "Questão 63\n",
      "C\n",
      "Questão 64\n",
      "A\n",
      "Questão 65\n",
      "E\n",
      "Questão 66\n",
      "E\n",
      "Questão 67\n",
      "B\n",
      "Questão 68\n",
      "D\n",
      "Questão 69\n",
      "A \n",
      "Questão 70\n",
      "D\n",
      "Questão 71\n",
      "D\n",
      "Questão 72\n",
      "E\n",
      "Questão 73\n",
      "C\n",
      "Questão 74\n",
      "C\n",
      "Questão 75\n",
      "C\n",
      "Questão 76\n",
      "C \n",
      "Questão 77\n",
      "A\n",
      "Questão 78\n",
      "B\n",
      "Questão 79\n",
      "E\n",
      "Questão 80\n",
      "B\n",
      "Questão 81\n",
      "C\n",
      "Questão 82\n",
      "B\n",
      "Questão 83\n",
      "B\n",
      "Questão 84\n",
      "B\n",
      "Questão 85\n",
      "A\n",
      "Questão 86\n",
      "D\n",
      "Questão 87\n",
      "E\n",
      "Questão 88\n",
      "A\n",
      "Questão 89\n",
      "D\n",
      "Questão 90\n",
      "C\n",
      "Questão 91I\n",
      "E\n",
      "Questão 92I\n",
      "D\n",
      "Questão 93I\n",
      "D\n",
      "Questão 94I\n",
      "E\n",
      "Questão 95I\n",
      "B\n",
      "Questão 91E\n",
      "D\n",
      "Questão 92E\n",
      "D\n",
      "Questão 93E\n",
      "B\n",
      "Questão 94E\n",
      "A\n",
      "Questão 95E\n",
      "C\n",
      "Questão 96\n",
      "C\n",
      "Questão 97\n",
      "E\n",
      "Questão 98\n",
      "A\n",
      "Questão 99\n",
      "C\n",
      "Questão 100\n",
      "E\n",
      "Questão 101\n",
      "C\n",
      "Questão 102\n",
      "D\n",
      "Questão 103\n",
      "A\n",
      "Questão 104\n",
      "A\n",
      "Questão 105\n",
      "A \n",
      "Questão 106\n",
      "C\n",
      "Questão 107\n",
      "E\n",
      "Questão 108\n",
      "E\n",
      "Questão 109\n",
      "B\n",
      "Questão 110\n",
      "B\n",
      "Questão 111\n",
      "A\n",
      "Questão 112\n",
      "D\n",
      "Questão 113\n",
      "D\n",
      "Questão 114\n",
      "B\n",
      "Questão 115\n",
      "D\n",
      "Questão 116\n",
      "C\n",
      "Questão 117\n",
      "E\n",
      "Questão 118\n",
      "E \n",
      "Questão 119\n",
      "B\n",
      "Questão 120\n",
      "A\n",
      "Questão 121\n",
      "E\n",
      "Questão 122\n",
      "D \n",
      "Questão 123\n",
      "B\n",
      "Questão 124\n",
      "B\n",
      "Questão 125\n",
      "B\n",
      "Questão 126\n",
      "D\n",
      "Questão 127\n",
      "E\n",
      "Questão 128\n",
      "A\n",
      "Questão 129\n",
      "C\n",
      "Questão 130\n",
      "E \n",
      "Questão 131\n",
      "B\n",
      "Questão 132\n",
      "E\n",
      "Questão 133\n",
      "E\n",
      "Questão 134\n",
      "E\n",
      "Questão 135\n",
      "E\n",
      "Questão 136\n",
      "C\n",
      "Questão 137\n",
      "D\n",
      "Questão 138\n",
      "D\n",
      "Questão 139\n",
      "C\n",
      "Questão 140\n",
      "C\n",
      "Questão 141\n",
      "C 80 minutos.\n",
      "Questão 142\n",
      "E\n",
      "Questão 143\n",
      "C\n",
      "Questão 144\n",
      "B\n",
      "Questão 145\n",
      "B\n",
      "Questão 146\n",
      "C\n",
      "Questão 147\n",
      "E (5, 0).\n",
      "Questão 148\n",
      "D\n",
      "Questão 149\n",
      "C (–2, 1)\n",
      "Questão 150\n",
      "C\n",
      "Questão 151\n",
      "D\n",
      "Questão 152\n",
      "B\n",
      "Questão 153\n",
      "D\n",
      "Questão 154\n",
      "C \n",
      "Questão 155\n",
      "D\n",
      "Questão 156\n",
      "C.\n",
      "Questão 157\n",
      "C\n",
      "Questão 158\n",
      "E.\n",
      "Questão 159\n",
      "D 42 000\n",
      "Questão 160\n",
      "B\n",
      "Questão 161\n",
      "B\n",
      "Questão 162\n",
      "A\n",
      "Questão 163\n",
      "C\n",
      "Questão 164\n",
      "D\n",
      "Questão 165\n",
      "C\n",
      "Questão 166\n",
      "A\n",
      "Questão 167\n",
      "C\n",
      "Questão 168\n",
      "D\n",
      "Questão 169\n",
      "D\n",
      "Questão 170\n",
      "B\n",
      "Questão 171\n",
      "B 9%.\n",
      "Questão 172\n",
      "C\n",
      "Questão 173\n",
      "A Resposta correta é: A\n",
      "Questão 174\n",
      "C\n",
      "Questão 175\n",
      "C\n",
      "Questão 176\n",
      "A\n",
      "Questão 177\n",
      "D\n",
      "Questão 178\n",
      "D\n",
      "Questão 179\n",
      "D K, J, H, I, G\n",
      "Questão 180\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "CSVS_PATH = '../TCC/csvs'\n",
    "EXPERIMENTS_PATH = '../TCC/experiments'\n",
    "EXPERIMENT_NUMBER = 1\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "years = [2011]\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    enem_csv = pd.read_csv(f'{CSVS_PATH}/enem_{year}_questions.csv').copy()\n",
    "    model_answers = ''    \n",
    "    problematic_questions = []\n",
    "    problematic_outputs = []\n",
    "    \n",
    "    for index, row in enem_csv.iterrows():\n",
    "        # print(index)\n",
    "        # if (index > 184 or index < 178 ):\n",
    "        #     continue\n",
    "        question = row['body']\n",
    "        alternatives = row['alternatives']\n",
    "        prompt = f'usando como base esse enunciado: {question} \\n responda qual a alternativa correta, entre as opções a seguir: \\n {alternatives} \\n a alternativa correta é:'\n",
    "        teste = ''\n",
    "        print(f'Questão {row[\"id\"]}')\n",
    "        try:\n",
    "            \n",
    "            teste = submit_questions(prompt)\n",
    "            print(teste)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            problematic_questions.append(row['id'])\n",
    "            \n",
    "            with open(f'{EXPERIMENTS_PATH}/{EXPERIMENT_NUMBER}/{year}/GPT3.5_{year}_answers.txt', 'w+',encoding='utf-8') as f:\n",
    "                f.write(model_answers)\n",
    "                \n",
    "        model_answers += f'{row[\"id\"]}\\n{teste}\\n'\n",
    "        sleep(20)\n",
    "    \n",
    "    model_answers += f'\\nQuestões problemáticas: {problematic_questions}'\n",
    "    model_answers += f'\\nSaídas problemáticas: {problematic_outputs}'\n",
    "    \n",
    "    with open(f'{EXPERIMENTS_PATH}/{EXPERIMENT_NUMBER}/{year}/GPT3.5_{year}_answers.txt', 'w+',encoding='utf-8') as f:\n",
    "        f.write(model_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respondendo as questões não respondidas de primeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questão 06\n",
      "D\n",
      "Questão 07\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "enem_csv = pd.read_csv(f'{CSVS_PATH}/enem_{2016}_questions.csv').copy()\n",
    "\n",
    "model_answers = ''    \n",
    "problematic_questions = []\n",
    "problematic_outputs = []\n",
    "\n",
    "for index, row in enem_csv.iterrows():\n",
    "\n",
    "        # print(index)\n",
    "        # if (index > 52 or index < 11 ) and (index > 146 or index < 141):\n",
    "        #     continue\n",
    "        if(index > 6 or index < 5):\n",
    "            continue\n",
    "        question = row['body']\n",
    "        alternatives = row['alternatives']\n",
    "        prompt = f'usando como base esse enunciado: {question} \\n responda qual a alternativa correta, entre as opções a seguir: \\n {alternatives} \\n a alternativa correta é:'\n",
    "        teste = ''\n",
    "        print(f'Questão {row[\"id\"]}')\n",
    "        try:\n",
    "            \n",
    "            teste = submit_questions(prompt)\n",
    "            print(teste)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            problematic_questions.append(row['id'])\n",
    "            \n",
    "            with open(f'{EXPERIMENTS_PATH}/{EXPERIMENT_NUMBER}/{2016}/GPT3.5_{2016}_problematic_answers.txt', 'w+',encoding='utf-8') as f:\n",
    "                f.write(model_answers)\n",
    "                \n",
    "        model_answers += f'{row[\"id\"]}\\n{teste}\\n'\n",
    "        sleep(20)\n",
    "    \n",
    "model_answers += f'\\nQuestões problemáticas: {problematic_questions}'\n",
    "model_answers += f'\\nSaídas problemáticas: {problematic_outputs}'\n",
    "\n",
    "with open(f'{EXPERIMENTS_PATH}/{EXPERIMENT_NUMBER}/{2016}/GPT3.5_{2016}_problematic_answers.txt', 'w+',encoding='utf-8') as f:\n",
    "    f.write(model_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
